import os
import torch
import requests
from PIL import Image
from diffusers import StableDiffusionPipeline, UNet2DConditionModel
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from torch.optim import AdamW
from tqdm import tqdm
import time

# 1. è®¾ç½®è·¯å¾„
SAVE_PATH = "D:\\baiduç«èµ›\\cifar-10-images"
MODEL_PATH = "D:\\stable-diffusion-v1-4"
FINETUNE_OUTPUT = "D:\\stable-diffusion-finetuned"

# 2. ç”Ÿæˆæ–‡æœ¬æè¿°ï¼ˆAPIï¼‰
API_KEY = os.getenv("API_KEY")  # ä»ç¯å¢ƒå˜é‡è·å– API å¯†é’¥
if API_KEY is None:
    raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ API_KEY")
API_URL = "https://aistudio.baidu.com/llm/lmapi/v3/chat/completions"

def generate_text(dataset_name="CIFAR-10", max_tokens=100):
    prompt = f"è¯·æ ¹æ® {dataset_name} æ•°æ®é›†çš„ç±»åˆ«ï¼Œç”Ÿæˆ 5 ä¸ªæè¿°æ¸…æ™°ã€å…·ä½“çš„å›¾ç‰‡è¯´æ˜ï¼Œä¾‹å¦‚ï¼š'ä¸€åªçº¢è‰²çš„å¡é€šé¸Ÿåœ¨è“å¤©é£ç¿”' æˆ– 'ä¸€è¾†ç»¿è‰²çš„å¡è½¦åœåœ¨å…¬è·¯ä¸Š'ï¼Œæ¯ä¸ªä¸è¶…è¿‡ 30 å­—ï¼Œä¸è¦ç¼–å·ã€‚"

    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "model": "ernie-3.5-8k",
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": max_tokens
    }

    for attempt in range(5):
        response = requests.post(API_URL, json=data, headers=headers)
        if response.status_code == 200:
            result = response.json()
            return result.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
        elif response.status_code == 403:
            print(f"âš ï¸ API è®¿é—®å—é™ï¼ˆ403ï¼‰ï¼Œç­‰å¾… 5 ç§’åé‡è¯•ï¼ˆç¬¬ {attempt + 1} æ¬¡ï¼‰...")
            time.sleep(5)
        else:
            print(f"API Error: {response.status_code} - {response.text}")
            return None

    print("âŒ API å¤±è´¥ï¼Œé€€å‡º")
    exit(1)

#  3. åŠ è½½ Stable Diffusion
print("ğŸ”„ åŠ è½½ Stable Diffusion æ¨¡å‹...")
pipe = StableDiffusionPipeline.from_pretrained(MODEL_PATH, local_files_only=True)
pipe.to("cpu")
print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")

# 4. åŠ è½½ UNet
unet = UNet2DConditionModel.from_pretrained(MODEL_PATH, subfolder="unet")

# 5. è®­ç»ƒæ•°æ®é›†
class Cifar10Dataset(Dataset):
    def __init__(self, image_dir, limit=500):  # é€‚å½“å¢åŠ æ•°æ®é‡ï¼Œæé«˜å¾®è°ƒè´¨é‡
        self.image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir)][:limit]
        self.transform = transforms.Compose([
            transforms.Resize((256, 256)),  # **ä¼˜åŒ–åˆ†è¾¨ç‡**
            transforms.ToTensor()
        ])

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img = Image.open(self.image_paths[idx]).convert("RGB")
        return self.transform(img)

dataset = Cifar10Dataset(SAVE_PATH, limit=500)
dataloader = DataLoader(dataset, batch_size=8, shuffle=True)  # **æ‰¹é‡å¤§å°æ”¹ä¸º 8ï¼ŒCPU å‹å¥½**

# 6. é…ç½®ä¼˜åŒ–å™¨
optimizer = AdamW(unet.parameters(), lr=3e-6)  # **é™ä½å­¦ä¹ ç‡ï¼Œæé«˜ç¨³å®šæ€§**

# 7. è®­ç»ƒ
epochs = 2  # é€‚å½“å¢åŠ  epochï¼Œç¡®ä¿è®­ç»ƒæ•ˆæœ
print("ğŸ”¥ å¼€å§‹å¾®è°ƒ UNetï¼ˆä¼˜åŒ–ç‰ˆï¼‰...")

text_encoder = pipe.text_encoder
tokenizer = pipe.tokenizer

for epoch in range(epochs):
    print(f"ğŸš€ Epoch {epoch + 1}/{epochs} å¼€å§‹...")

    progress_bar = tqdm(total=len(dataset), desc=f"Epoch {epoch + 1} è¿›åº¦", ncols=100, leave=True)

    for idx, img in enumerate(dataloader):
        img = img.to("cpu")

        # ğŸš€ ç”Ÿæˆæ—¶é—´æ­¥ & æ–‡æœ¬åµŒå…¥
        timestep = torch.randint(0, 1000, (img.shape[0],), dtype=torch.long, device="cpu")
        text_inputs = tokenizer(
            ["A high-quality CIFAR-10 image"] * img.shape[0],
            padding="max_length",
            max_length=tokenizer.model_max_length,
            truncation=True,
            return_tensors="pt"
        ).to("cpu")
        encoder_hidden_states = text_encoder(text_inputs.input_ids)[0]

        # ğŸš€ ç”Ÿæˆå™ªå£° (batch_size, 4, 64, 64)
        noise = torch.randn((img.shape[0], 4, 64, 64)).to("cpu")

        # ğŸš€ è®¡ç®— UNet è¾“å‡ºï¼ˆæ— æ¢¯åº¦è®¡ç®—ï¼‰
        with torch.no_grad():
            output = unet(sample=noise, timestep=timestep, encoder_hidden_states=encoder_hidden_states)

        loss = output.sample.mean()

        # âœ… æ¯ 10 ä¸ª batch æ‰“å° `Loss`
        if idx % 10 == 0:
            print(f"ğŸš€ Batch {idx}/{len(dataset)}: Loss={loss.item():.4f}")

        progress_bar.update(img.shape[0])

    progress_bar.close()
    print(f"âœ… Epoch {epoch + 1} è®­ç»ƒå®Œæˆï¼")

# 8. ä»…ä¿å­˜ UNet
os.makedirs(FINETUNE_OUTPUT, exist_ok=True)
unet.save_pretrained(os.path.join(FINETUNE_OUTPUT, "unet"))
print("ğŸ‰ UNet å¾®è°ƒå®Œæˆï¼Œå·²ä¿å­˜ï¼")

# 9. é‡æ–°åŠ è½½ Stable Diffusion å¹¶æ›¿æ¢ UNet
print("ğŸ”„ é‡æ–°åŠ è½½ Stable Diffusion å¹¶æ›¿æ¢ UNet...")
pipe = StableDiffusionPipeline.from_pretrained(MODEL_PATH, local_files_only=True)
pipe.unet = UNet2DConditionModel.from_pretrained(os.path.join(FINETUNE_OUTPUT, "unet"))
pipe.to("cpu")
print("âœ… å¾®è°ƒåæ¨¡å‹åŠ è½½å®Œæˆï¼")

def generate_image(prompt, index):
    print(f"ğŸ–¼ï¸ ç”Ÿæˆå›¾ç‰‡ {index + 1}/5 ...")
    image = pipe(prompt).images[0]
    image_path = f"finetuned_ai_generated_{index + 1}.png"
    image.save(image_path)
    print(f"âœ… å›¾ç‰‡å·²ä¿å­˜ä¸º: {image_path}")

# 10. è¿è¡Œ
descriptions = generate_text(dataset_name="CIFAR-10", max_tokens=150)
descriptions = descriptions.split("\n")[:5]
print("âœ… AI ç”Ÿæˆçš„æ–‡æœ¬æè¿°:")
for i, desc in enumerate(descriptions, 1):
    print(f"  {i}. {desc.strip()}")

for idx, desc in enumerate(descriptions):
    generate_image(desc, idx)

print("ğŸ‰ æ‰€æœ‰å›¾ç‰‡ç”Ÿæˆå®Œæ¯•ï¼")
